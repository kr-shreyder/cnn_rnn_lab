# Лабораторная работа: Генерация подписей к изображениям (RNN/LSTM)

В этом задании реализовывана модель создания подписей на естественном языке к изображениям. Модель объединяет сверточные нейронные сети (CNN) для выделения признаков изображения и рекуррентные нейронные сети (RNN) для генерации подписей.

## Структура проекта
- `requirements.txt`: Список необходимых библиотек.
- `coco_utils.py`: Вспомогательный скрипт для загрузки данных.
- `/notebooks/img_captioning.ipynb`: Jupyter Notebook c основным кодом проекта.

## Настройка и запуск

### 1. Загрузка данных
**Внимание:** Датасет не включен в репозиторий из-за большого размера.
1.  Скачайте архив с данными (~1 Гб) по ссылке: [http://labcolor.space/coco_captioning.zip](http://labcolor.space/coco_captioning.zip)
2.  Создайте в корне проекта папку `data`.
3.  Внутри нее создайте папку `coco_captioning`.
4.  Распакуйте содержимое скачанного архива в папку `data/coco_captioning/`.

### 2. Установка зависимостей
Для запуска и воспроизведения проекта рекомендуется использовать виртуальное окружение.
Создание виртуального окружения (venv)

`python3 -m venv venv`

Активация окружения (для macOS/Linux)

`source venv/bin/activate`

Активация окружения (для Windows PowerShell)

`source .\venv\Scripts\Activate`

Установите все необходимые библиотеки из файла requirements.txt

`pip install -r requirements.txt`

# Выводы

В ходе данной лабораторной работы была реализована модель для генерации подписей к изображениям (Image Captioning) на основе архитектуры CNN+RNN.

### 1. Реализованные архитектуры
Были реализованы и сравнены две архитектуры для объединения признаков изображения и текстовых данных, описанные в статье "Where to put the Image in an Image Caption Generator":
1.  **(a) Init-inject:** Вектор признаков изображения используется для инициализации начального скрытого состояния LSTM-декодера.
2.  **(b) Pre-inject:** Вектор признаков изображения подается как самый первый элемент последовательности на вход LSTM.

### 2. Обучение
Обе модели обучались в одинаковых условиях для честного сравнения: 3 эпохи на полном обучающем датасете COCO с использованием GPU. В процессе обучения отслеживалась функция потерь (Cross-Entropy Loss) на обучающей и валидационной выборках. Было экспериментально установлено, что обучение более 3-х эпох приводит к **переобучению** (росту `Val Loss`).

### 3. Сравнение моделей
Сравнение проводилось как визуально, так и с помощью стандартной метрики **BLEU**.

-   **Визуальная оценка:** Модель `Init-inject` генерировала более длинные, осмысленные и релевантные изображениям подписи. Модель `Pre-inject` часто генерировала лишь 2-3 слова и обрывалась на токенах `<UNK>`.
-   **Оценка BLEU:** Численные результаты полностью подтвердили визуальные наблюдения. Модель `Init-inject` показала значительно лучшие результаты по всем метрикам BLEU.

| Метрика | Init-inject | Pre-inject |
| :--- | :---: | :---: |
| **BLEU-1** | **0.2743** | 0.1414 |
| **BLEU-2** | **0.1384** | 0.0374 |
| **BLEU-3** | **0.0828** | 0.0233 |
| **BLEU-4** | **0.0578** | 0.0201 |

### В итоге
Экспериментально установлено, что для данной задачи архитектура **Init-inject** является значительно более эффективной. Она быстрее сходится (показывает меньший `Loss`) и генерирует более качественные и полные подписи, что подтверждается как визуальной оценкой, так и метрикой BLEU.